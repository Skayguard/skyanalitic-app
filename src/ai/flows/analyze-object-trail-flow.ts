
'use server';
/**
 * @fileOverview Analyzes a video to identify a moving object, describe its trail,
 * and attempt to generate an image representing this trail.
 *
 * - analyzeObjectTrail - A function that handles the object trail analysis process.
 * - AnalyzeObjectTrailInput - The input type for the analyzeObjectTrail function.
 * - AnalyzeObjectTrailOutput - The return type for the analyzeObjectTrail function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const AnalyzeObjectTrailInputSchema = z.object({
  videoDataUri: z
    .string()
    .describe(
      "A video of a potential UAP or object in motion, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'."
    ),
});
export type AnalyzeObjectTrailInput = z.infer<typeof AnalyzeObjectTrailInputSchema>;

const AnalyzeObjectTrailOutputSchema = z.object({
  trailDescription: z.string().describe('A textual description of the identified object\'s trail, including trajectory, speed, and visual characteristics.'),
  trailImageUri: z.string().optional().describe('A data URI of an image generated by AI representing the object\'s trail. Format: "data:image/png;base64,<encoded_data>". This is optional and might not be generated if the model cannot produce a relevant image.'),
  errorMessage: z.string().optional().describe('An optional message if there were issues or specific limitations encountered during analysis (e.g., image generation failed).'),
});
export type AnalyzeObjectTrailOutput = z.infer<typeof AnalyzeObjectTrailOutputSchema>;

export async function analyzeObjectTrail(input: AnalyzeObjectTrailInput): Promise<AnalyzeObjectTrailOutput> {
  return analyzeObjectTrailFlow(input);
}

const analyzeObjectTrailFlow = ai.defineFlow(
  {
    name: 'analyzeObjectTrailFlow',
    inputSchema: AnalyzeObjectTrailInputSchema,
    outputSchema: AnalyzeObjectTrailOutputSchema,
  },
  async (input) => {
    try {
      // First, generate the textual description of the trail.
      const descriptionPrompt = ai.definePrompt({
        name: 'generateTrailDescriptionPrompt',
        input: { schema: AnalyzeObjectTrailInputSchema },
        output: { schema: z.object({ description: z.string() }) },
        prompt: `Analise o seguinte vídeo: {{media url=videoDataUri}}.
        Responda em português do Brasil.
        Identifique o objeto em movimento principal. Descreva seu rastro ou caminho de movimento em detalhes.
        Inclua informações sobre sua trajetória aparente, quaisquer mudanças de direção ou velocidade,
        e suas características visuais enquanto se move. Se houver múltiplos objetos, foque no mais proeminente ou anômalo.
        Se nenhum objeto em movimento claro ou rastro puder ser identificado, afirme isso.`,
         // Using the default model specified in ai configuration (gemini-2.0-flash)
      });

      const { output: descriptionOutput } = await descriptionPrompt(input);
      const trailDescription = descriptionOutput?.description || "Não foi possível gerar uma descrição do rastro a partir do vídeo.";

      // Then, attempt to generate an image of the trail using Gemini 2.0 Flash with image generation capabilities.
      let trailImageUri: string | undefined = undefined;
      let imageGenErrorMessage: string | undefined = undefined;
      
      try {
        const imageGenResponse = await ai.generate({
            model: 'googleai/gemini-2.0-flash-exp',
            prompt: `Baseado na análise deste vídeo: {{media url=videoDataUri}}, e focando no rastro do objeto em movimento principal que foi descrito como: "${trailDescription}".
            Gere uma única imagem que represente visualmente o rastro deste objeto. A imagem deve retratar o objeto em vários pontos ao longo de sua trajetória, sobreposto a um fundo que reflita o cenário geral do vídeo.
            Isso deve criar um efeito de "rastro de movimento" ou "longa exposição" para o objeto.
            Se o vídeo for muito complexo, ou o objeto não estiver claro, ou você não puder razoavelmente criar tal imagem de rastro, produza um placeholder simples ou indique falha na parte textual da sua resposta.
            Qualquer texto na sua resposta deve ser em português do Brasil.`,
            config: {
              responseModalities: ['TEXT', 'IMAGE'], 
            },
        });
        
        if (imageGenResponse.media && imageGenResponse.media.url) {
            trailImageUri = imageGenResponse.media.url;
        } else if (imageGenResponse.text) {
            imageGenErrorMessage = `O modelo respondeu sobre a geração da imagem: "${imageGenResponse.text}". Nenhuma imagem de rastro foi gerada.`;
        } else {
            imageGenErrorMessage = "A geração da imagem do rastro não produziu um resultado visual, ou o formato não é suportado. O modelo pode não ter conseguido criar a imagem solicitada.";
        }

      } catch (e) {
        console.error("Error during trail image generation:", e);
        imageGenErrorMessage = `Ocorreu um erro técnico ao tentar gerar a imagem do rastro: ${(e as Error).message}.`;
      }

      return {
        trailDescription: trailDescription,
        trailImageUri: trailImageUri,
        errorMessage: imageGenErrorMessage,
      };

    } catch (flowError) {
      console.error("Error in analyzeObjectTrailFlow:", flowError);
      return {
        trailDescription: "Falha ao analisar o rastro do objeto.",
        trailImageUri: undefined,
        errorMessage: `Erro no fluxo de análise: ${(flowError as Error).message}`,
      };
    }
  }
);
