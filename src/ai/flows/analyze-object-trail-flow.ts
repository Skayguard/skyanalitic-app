
'use server';
/**
 * @fileOverview Analyzes a video to identify a moving object, describe its trail,
 * and attempt to generate an image representing this trail.
 *
 * - analyzeObjectTrail - A function that handles the object trail analysis process.
 * - AnalyzeObjectTrailInput - The input type for the analyzeObjectTrail function.
 * - AnalyzeObjectTrailOutput - The return type for the analyzeObjectTrail function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const AnalyzeObjectTrailInputSchema = z.object({
  videoDataUri: z
    .string()
    .describe(
      "A video of a potential UAP or object in motion, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'."
    ),
});
export type AnalyzeObjectTrailInput = z.infer<typeof AnalyzeObjectTrailInputSchema>;

const AnalyzeObjectTrailOutputSchema = z.object({
  trailDescription: z.string().describe('A textual description of the identified object\'s trail, including trajectory, speed, and visual characteristics.'),
  trailImageUri: z.string().optional().describe('A data URI of an image generated by AI representing the object\'s trail. Format: "data:image/png;base64,<encoded_data>". This is optional and might not be generated if the model cannot produce a relevant image.'),
  errorMessage: z.string().optional().describe('An optional message if there were issues or specific limitations encountered during analysis (e.g., image generation failed).'),
});
export type AnalyzeObjectTrailOutput = z.infer<typeof AnalyzeObjectTrailOutputSchema>;

export async function analyzeObjectTrail(input: AnalyzeObjectTrailInput): Promise<AnalyzeObjectTrailOutput> {
  return analyzeObjectTrailFlow(input);
}

const analyzeObjectTrailFlow = ai.defineFlow(
  {
    name: 'analyzeObjectTrailFlow',
    inputSchema: AnalyzeObjectTrailInputSchema,
    outputSchema: AnalyzeObjectTrailOutputSchema,
  },
  async (input) => {
    try {
      // First, generate the textual description of the trail.
      const descriptionPrompt = ai.definePrompt({
        name: 'generateTrailDescriptionPrompt',
        input: { schema: AnalyzeObjectTrailInputSchema },
        output: { schema: z.object({ description: z.string() }) },
        prompt: `Analyze the following video: {{media url=videoDataUri}}.
        Identify the primary moving object. Describe its trail or path of motion in detail.
        Include information about its apparent trajectory, any changes in direction or speed,
        and its visual characteristics as it moves. If there are multiple objects, focus on the most prominent or anomalous one.
        If no clear moving object or trail can be identified, state that.`,
         // Using the default model specified in ai configuration (gemini-2.0-flash)
      });

      const { output: descriptionOutput } = await descriptionPrompt(input);
      const trailDescription = descriptionOutput?.description || "Não foi possível gerar uma descrição do rastro a partir do vídeo.";

      // Then, attempt to generate an image of the trail using Gemini 2.0 Flash with image generation capabilities.
      // This is experimental and might not always produce the desired result.
      let trailImageUri: string | undefined = undefined;
      let imageGenErrorMessage: string | undefined = undefined;
      
      try {
        const imageGenResponse = await ai.generate({
            model: 'googleai/gemini-2.0-flash-exp', // Explicitly use the image-capable experimental model
            prompt: `Based on the analysis of this video: {{media url=videoDataUri}}, and focusing on the primary moving object's trail that was described as: "${trailDescription}".
            Generate a single image that visually represents this object's trail. The image should depict the object at several points along its trajectory, superimposed onto a background that reflects the general scenery of the video.
            This should create a "motion trail" or "long exposure" effect for the object.
            If the video is too complex, or the object is not clear, or you cannot reasonably create such a trail image, output a simple placeholder or indicate failure in the text part of your response.`,
            config: {
              responseModalities: ['TEXT', 'IMAGE'], // Request both text (for potential error/fallback) and image
              // Add safety settings if needed, e.g. to be less restrictive if it helps generation
              // safetySettings: [{ category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_NONE' }] 
            },
        });
        
        if (imageGenResponse.media && imageGenResponse.media.url) {
            trailImageUri = imageGenResponse.media.url;
        } else if (imageGenResponse.text) {
            imageGenErrorMessage = `O modelo respondeu sobre a geração da imagem: "${imageGenResponse.text}". Nenhuma imagem de rastro foi gerada.`;
        } else {
            imageGenErrorMessage = "A geração da imagem do rastro não produziu um resultado visual, ou o formato não é suportado. O modelo pode não ter conseguido criar a imagem solicitada.";
        }

      } catch (e) {
        console.error("Error during trail image generation:", e);
        imageGenErrorMessage = `Ocorreu um erro técnico ao tentar gerar a imagem do rastro: ${(e as Error).message}.`;
      }

      return {
        trailDescription: trailDescription,
        trailImageUri: trailImageUri,
        errorMessage: imageGenErrorMessage,
      };

    } catch (flowError) {
      console.error("Error in analyzeObjectTrailFlow:", flowError);
      return {
        trailDescription: "Falha ao analisar o rastro do objeto.",
        trailImageUri: undefined,
        errorMessage: `Erro no fluxo de análise: ${(flowError as Error).message}`,
      };
    }
  }
);
